{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sdgsdg\n",
    "\n",
    "# This panel uses Markdown\n",
    "https://en.wikipedia.org/wiki/Markdown\n",
    "\n",
    "##sdfsdf\n",
    "\n",
    "* Note: I need to re-name the Main.offence column in the csv files to 'MainOffence'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section must be included at the beginning of each new notebook. Remember to change the app name. \n",
    "# If you're using VirtualBox, change the below to '/home/user/spark-2.1.1-bin-hadoop2.7'\n",
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('childandyouthjustice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's read in the data. If you open the dataset, you'll find that each column has a header. We specify that by stating that header=True.\n",
    "# To make our lives easier, we can also use 'inferSchema' when importing CSVs. This automatically detects data types.\n",
    "# If you would like to manually change data types, refer to this article: https://medium.com/@mrpowers/adding-structtype-columns-to-spark-dataframes-b44125409803\n",
    "#\n",
    "# Child and Youth Court Charges / Outcome\n",
    "df_7361 = spark.read.csv('Datasets/7361_repeated.csv',header=True,inferSchema=True)\n",
    "\n",
    "# Child and Youth Court Orders\n",
    "df_7362 = spark.read.csv('Datasets/7362_repeated.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+--------------------+---+------+---------+--------------------+-----+-----+\n",
      "|    _c0|Year|         MainOffence|Age|Gender|Ethnicity|             Outcome|Value|Flags|\n",
      "+-------+----+--------------------+---+------+---------+--------------------+-----+-----+\n",
      "| 2892.0|1992|Public Order Offe...| 14|Female| European|Convicted and sen...|    1|   NA|\n",
      "| 2602.0|1992|Unlawful Entry Wi...| 14|Female| European|           Dismissed|    1|   NA|\n",
      "| 2648.0|1992|Theft And Related...| 14|Female| European|Youth Court prove...|    1|   NA|\n",
      "| 2558.0|1992|Unlawful Entry Wi...| 14|Female| European|Youth Court prove...|    1|   NA|\n",
      "| 2838.0|1992|Property Damage A...| 14|Female| European|Youth Court prove...|    1|   NA|\n",
      "| 2672.0|1992|Theft And Related...| 14|Female| European|Youth Court prove...|    1|   NA|\n",
      "| 2582.0|1992|Unlawful Entry Wi...| 14|Female| European|Youth Court prove...|    1|   NA|\n",
      "|20523.0|1992|Dangerous Or Negl...| 15|Female| European|Convicted and sen...|    1|   NA|\n",
      "|20955.0|1992|Illicit Drug Offe...| 15|Female| European|Convicted and sen...|    1|   NA|\n",
      "|21302.0|1992|Offences Against ...| 15|Female| European|Convicted and sen...|    1|   NA|\n",
      "|20946.0|1992|Illicit Drug Offe...| 15|Female| European|           Dismissed|    1|   NA|\n",
      "|21312.0|1992|Miscellaneous Off...| 15|Female| European|       Other outcome|    1|   NA|\n",
      "|20507.0|1992|Dangerous Or Negl...| 15|Female| European|           Withdrawn|    1|   NA|\n",
      "|20908.0|1992|Fraud, Deception ...| 15|Female| European|           Withdrawn|    1|   NA|\n",
      "|20818.0|1992|Theft And Related...| 15|Female| European|           Withdrawn|    1|   NA|\n",
      "|20364.0|1992|Acts Intended To ...| 15|Female| European|Youth Court prove...|    1|   NA|\n",
      "|20871.0|1992|Fraud, Deception ...| 15|Female| European|Youth Court prove...|    1|   NA|\n",
      "|21027.0|1992|Property Damage A...| 15|Female| European|Youth Court prove...|    1|   NA|\n",
      "|21103.0|1992|Public Order Offe...| 15|Female| European|Youth Court prove...|    1|   NA|\n",
      "|20766.0|1992|Theft And Related...| 15|Female| European|Youth Court prove...|    1|   NA|\n",
      "+-------+----+--------------------+---+------+---------+--------------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+-------+----+---+--------------------+------+---------+--------------------+-----+-----+\n",
      "|    _c0|Year|Age|         MainOffence|Gender|Ethnicity|               Order|Value|Flags|\n",
      "+-------+----+---+--------------------+------+---------+--------------------+-----+-----+\n",
      "| 1633.0|1992| 14|Theft And Related...|Female| European| Discharge, admonish|    1|   NA|\n",
      "| 1674.0|1992| 14|Public Order Offe...|Female| European|Monetary, confisc...|    1|   NA|\n",
      "| 1660.0|1992| 14|Property Damage A...|Female| European|Supervision with ...|    1|   NA|\n",
      "| 1615.0|1992| 14|Theft And Related...|Female| European|Supervision, comm...|    1|   NA|\n",
      "| 1574.0|1992| 14|Unlawful Entry Wi...|Female| European|Supervision, comm...|    1|   NA|\n",
      "|13857.0|1992| 15|Illicit Drug Offe...|Female| European|     Adult sentences|    1|   NA|\n",
      "|13636.0|1992| 15|Dangerous Or Negl...|Female| European|Monetary, confisc...|    1|   NA|\n",
      "|13982.0|1992| 15|Offences Against ...|Female| European|Monetary, confisc...|    1|   NA|\n",
      "|13912.0|1992| 15|Public Order Offe...|Female| European|Monetary, confisc...|    1|   NA|\n",
      "|13788.0|1992| 15|Theft And Related...|Female| European|Monetary, confisc...|    1|   NA|\n",
      "|13883.0|1992| 15|Property Damage A...|Female| European|Supervision with ...|    1|   NA|\n",
      "|13666.0|1992| 15|Abduction, Harass...|Female| European|Supervision, comm...|    1|   NA|\n",
      "|13587.0|1992| 15|Acts Intended To ...|Female| European|Supervision, comm...|    1|   NA|\n",
      "|13911.0|1992| 15|Public Order Offe...|Female| European|Supervision, comm...|    1|   NA|\n",
      "|13772.0|1992| 15|Theft And Related...|Female| European|Supervision, comm...|    1|   NA|\n",
      "|30681.0|1992| 16|Acts Intended To ...|Female| European|     Adult sentences|    1|   NA|\n",
      "|31079.0|1992| 16|Fraud, Deception ...|Female| European|     Adult sentences|    1|   NA|\n",
      "|30654.0|1992| 16|Homicide And Rela...|Female| European|     Adult sentences|    1|   NA|\n",
      "|30990.0|1992| 16|Theft And Related...|Female| European|     Adult sentences|    1|   NA|\n",
      "|30810.0|1992| 16|Dangerous Or Negl...|Female| European| Discharge, admonish|    1|   NA|\n",
      "+-------+----+---+--------------------+------+---------+--------------------+-----+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The show method allows you visualise DataFrames in a tabular format. \n",
    "#\n",
    "# Child and Youth Court Charges / Outcome\n",
    "df_7361.show()\n",
    "\n",
    "# Child and Youth Court Orders\n",
    "df_7362.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: double (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- MainOffence: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Outcome: string (nullable = true)\n",
      " |-- Value: integer (nullable = true)\n",
      " |-- Flags: string (nullable = true)\n",
      "\n",
      "[Row(_c0=2892.0, Year=1992, MainOffence='Public Order Offences', Age='14', Gender='Female', Ethnicity='European', Outcome='Convicted and sentenced in adult court', Value=1, Flags='NA')]\n",
      "root\n",
      " |-- _c0: double (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- MainOffence: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Ethnicity: string (nullable = true)\n",
      " |-- Order: string (nullable = true)\n",
      " |-- Value: integer (nullable = true)\n",
      " |-- Flags: string (nullable = true)\n",
      "\n",
      "[Row(_c0=1633.0, Year=1992, Age='14', MainOffence='Theft And Related Offences', Gender='Female', Ethnicity='European', Order='Discharge, admonish', Value=1, Flags='NA')]\n"
     ]
    }
   ],
   "source": [
    "# Child and Youth Court Charges / Outcome\n",
    "# Print schema allows us to visualise the data structure at a high level. \n",
    "df_7361.printSchema()\n",
    "\n",
    "# We can also use head to print a specific amount of rows, so we can get a better understanding of the data points. \n",
    "# Note that we have to specify 'print' depending on the method we're using. Otherwise it may not show up!\n",
    "print(df_7361.head(1))\n",
    "\n",
    "# Child and Youth Court Orders\n",
    "df_7362.printSchema()\n",
    "\n",
    "print(df_7362.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+------------------+--------------------+-------+---------+--------------------+------------------+-----+\n",
      "|summary|               _c0|              Year|               Age|         MainOffence| Gender|Ethnicity|               Order|             Value|Flags|\n",
      "+-------+------------------+------------------+------------------+--------------------+-------+---------+--------------------+------------------+-----+\n",
      "|  count|             32622|             32622|             32622|               32622|  32622|    32622|               32622|             32622|32622|\n",
      "|   mean|26272.849303384657|2002.6193059898228|  15.5182772460636|                null|   null|     null|                null|17.258966341732574| null|\n",
      "| stddev|11825.173925250825|  6.48640300177954|0.6864172219737754|                null|   null|     null|                null|24.965811669508636| null|\n",
      "|    min|              15.0|              1992|          12 to 13|Abduction, Harass...| Female| European|     Adult sentences|                 1|   NA|\n",
      "|    max|           51202.0|              2017|           Unknown|Unlawful Entry Wi...|Unknown|  Unknown|Supervision, comm...|               144|   NA|\n",
      "+-------+------------------+------------------+------------------+--------------------+-------+---------+--------------------+------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can use the describe method get some general statistics on our data too. \n",
    "#df_7361.describe().show()\n",
    "df_7362.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "\"cannot resolve '`Main.offence`' given input columns: [Flags, Gender, Age, MainOffence, Year, Ethnicity, Value, Outcome, _c0];;\\n'Project [Year#1, Age#3, 'Main.offence]\\n+- Relation[_c0#0,Year#1,MainOffence#2,Age#3,Gender#4,Ethnicity#5,Outcome#6,Value#7,Flags#8] csv\\n\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o30.select.\n: org.apache.spark.sql.AnalysisException: cannot resolve '`Main.offence`' given input columns: [Flags, Gender, Age, MainOffence, Year, Ethnicity, Value, Outcome, _c0];;\n'Project [Year#1, Age#3, 'Main.offence]\n+- Relation[_c0#0,Year#1,MainOffence#2,Age#3,Gender#4,Ethnicity#5,Outcome#6,Value#7,Flags#8] csv\n\n\tat org.apache.spark.sql.catalyst.analysis.package$AnalysisErrorAt.failAnalysis(package.scala:42)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:86)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1$$anonfun$apply$2.applyOrElse(CheckAnalysis.scala:83)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:290)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode$$anonfun$transformUp$1.apply(TreeNode.scala:290)\n\tat org.apache.spark.sql.catalyst.trees.CurrentOrigin$.withOrigin(TreeNode.scala:70)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.transformUp(TreeNode.scala:289)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$transformExpressionsUp$1.apply(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpression$1(QueryPlan.scala:266)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:276)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1$1.apply(QueryPlan.scala:280)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:234)\n\tat scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)\n\tat scala.collection.TraversableLike$class.map(TraversableLike.scala:234)\n\tat scala.collection.AbstractTraversable.map(Traversable.scala:104)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.org$apache$spark$sql$catalyst$plans$QueryPlan$$recursiveTransform$1(QueryPlan.scala:280)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan$$anonfun$6.apply(QueryPlan.scala:285)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.mapProductIterator(TreeNode.scala:188)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.mapExpressions(QueryPlan.scala:285)\n\tat org.apache.spark.sql.catalyst.plans.QueryPlan.transformExpressionsUp(QueryPlan.scala:255)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:83)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$$anonfun$checkAnalysis$1.apply(CheckAnalysis.scala:76)\n\tat org.apache.spark.sql.catalyst.trees.TreeNode.foreachUp(TreeNode.scala:128)\n\tat org.apache.spark.sql.catalyst.analysis.CheckAnalysis$class.checkAnalysis(CheckAnalysis.scala:76)\n\tat org.apache.spark.sql.catalyst.analysis.Analyzer.checkAnalysis(Analyzer.scala:57)\n\tat org.apache.spark.sql.execution.QueryExecution.assertAnalyzed(QueryExecution.scala:52)\n\tat org.apache.spark.sql.Dataset$.ofRows(Dataset.scala:63)\n\tat org.apache.spark.sql.Dataset.org$apache$spark$sql$Dataset$$withPlan(Dataset.scala:2845)\n\tat org.apache.spark.sql.Dataset.select(Dataset.scala:1131)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:280)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:214)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bd82e32e59c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# We see that the average age is 41. The average bank account balance is $1,074.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# And they spoke to call centre reps for approx. 931 seconds on average.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf_7361\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Year'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Main.offence'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;34m[\u001b[0m\u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Alice'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mu'Bob'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m         \"\"\"\n\u001b[0;32m--> 993\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jcols\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    994\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/spark-2.1.1-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     67\u001b[0m                                              e.java_exception.getStackTrace()))\n\u001b[1;32m     68\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.AnalysisException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'org.apache.spark.sql.catalyst.analysis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAnalysisException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: \"cannot resolve '`Main.offence`' given input columns: [Flags, Gender, Age, MainOffence, Year, Ethnicity, Value, Outcome, _c0];;\\n'Project [Year#1, Age#3, 'Main.offence]\\n+- Relation[_c0#0,Year#1,MainOffence#2,Age#3,Gender#4,Ethnicity#5,Outcome#6,Value#7,Flags#8] csv\\n\""
     ]
    }
   ],
   "source": [
    "# Let's select the columns that are integers, and use the describe method again.\n",
    "# We see that the average age is 41. The average bank account balance is $1,074. \n",
    "# And they spoke to call centre reps for approx. 931 seconds on average. \n",
    "df_7361.select('Year', 'Age', 'MainOffence').describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's select the balance column and assign it to a variable. \n",
    "Year_col = df_7361.select('Year')\n",
    "\n",
    "# We can then use the show method on that variable.\n",
    "Year_col.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
